#this is next step in twitter data analysis
#make sure to install textbob and WordCloud
# pip install textblob WordCloud

import pandas as pd
df = pd.read_csv('C:/Users/vang/Desktop/Python/AZNtwitter.csv')
df.head()

import re
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
import string
import nltk
import warnings 
warnings.filterwarnings("ignore", category=DeprecationWarning)

%matplotlib inline

#Clean the data
def remove_pattern(input_txt, pattern):
    r = re.findall(pattern, input_txt)
    for i in r:
        input_txt = re.sub(i, '', input_txt)
        
    return input_txt 
    
# remove twitter handles (@user)
df['tidy_tweet'] = np.vectorize(remove_pattern)(df['text'], "@[\w]*")


# remove special characters, numbers, punctuations
df['tidy_tweet'] = df['tidy_tweet'].str.replace("[^a-zA-Z#]", " ")

df['tidy_tweet'] = df['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))
df.head()


#tokenization
tokenized_tweet = df['tidy_tweet'].apply(lambda x: x.split())
tokenized_tweet.head()


#stemming
from nltk.stem.porter import *
stemmer = PorterStemmer()

tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming
tokenized_tweet.head()



for i in range(len(tokenized_tweet)):
    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])

df['tidy_tweet'] = tokenized_tweet
df.head()


## Define a function which can be applied to calculate the score for the whole dataset
import nltk
from nltk import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer
from wordcloud import WordCloud, STOPWORDS
from textblob import TextBlob


df.drop_duplicates(subset ='tidy_tweet', keep = "first", inplace = True)
df['tidy_tweet'] = df['tidy_tweet'].astype('str')
def get_polarity(text):
    return TextBlob(text).sentiment.polarity
df['Polarity'] = df['tidy_tweet'].apply(get_polarity)

df.head()


df['Sentiment_Type']=''
df.loc[df.Polarity>0,'Sentiment_Type']='POSITIVE'
df.loc[df.Polarity==0,'Sentiment_Type']='NEUTRAL'
df.loc[df.Polarity<0,'Sentiment_Type']='NEGATIVE'

df.head()

#get bar graph
df.Sentiment_Type.value_counts().plot(kind='bar',title="Sentiment Analysis")

#pie chart
plt.rcParams["figure.figsize"] = [10, 8]
df.Sentiment_Type.value_counts().plot(kind='pie', autopct='%1.0f%%')

all_words = ' '.join([text for text in df['tidy_tweet']])
from wordcloud import WordCloud
wordcloud = WordCloud(width=800, height=500, random_state=30, max_font_size=110).generate(all_words)

#wordcloud overall
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')

#postitive wordcloud
postitivewords =' '.join([text for text in df['tidy_tweet'][df['Sentiment_Type'] == 'POSITIVE']])

wordcloud = WordCloud(width=800, height=500, random_state=30, max_font_size=110).generate(postitivewords)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()
plt.show()

#netural wordcloud
neutralwords =' '.join([text for text in df['tidy_tweet'][df['Sentiment_Type'] == 'NEUTRAL']])

wordcloud = WordCloud(width=800, height=500, random_state=30, max_font_size=110).generate(neutralwords)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()


#negative wordcloud
negativewords =' '.join([text for text in df['tidy_tweet'][df['Sentiment_Type'] == 'NEGATIVE']])

wordcloud = WordCloud(width=800, height=500, random_state=10, max_font_size=110).generate(negativewords)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()
